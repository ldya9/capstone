{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf379d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT & SETUP\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20df8a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH CONFIG\n",
    "BASE_DATASET = Path(\"all_dataset\")\n",
    "BASE_RAW     = BASE_DATASET / \"raw_dataset\"\n",
    "BASE_CLEAN   = BASE_DATASET / \"clean_dataset\"\n",
    "\n",
    "# Buat folder kalau belum ada\n",
    "BASE_DATASET.mkdir(exist_ok=True)\n",
    "BASE_RAW.mkdir(exist_ok=True)\n",
    "BASE_CLEAN.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# LOAD FILES\n",
    "def load_all_files(domain_name=None):\n",
    "    files = list(BASE_RAW.glob(\"*.csv\"))\n",
    "    if domain_name:\n",
    "        files = [f for f in files if domain_name in f.stem]\n",
    "    if not files:\n",
    "        print(f\"[Warning] No CSV found for domain '{domain_name}'\")\n",
    "    data_dict = {f.stem: pd.read_csv(f) for f in files}\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3128769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL CLEANING HELPERS\n",
    "def to_datetime(df, cols):\n",
    "    for c in cols:\n",
    "        df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def to_numeric(df, cols):\n",
    "    for c in cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def clean_category(df, cols):\n",
    "    for c in cols:\n",
    "        df[c] = (\n",
    "            df[c]\n",
    "            .astype(str)\n",
    "            .str.strip()\n",
    "            .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "            .str.lower()\n",
    "        )\n",
    "    return df\n",
    "\n",
    "def clip_numeric(df, col, min_val=None, max_val=None):\n",
    "    if min_val is not None:\n",
    "        df[col] = df[col].clip(lower=min_val)\n",
    "    if max_val is not None:\n",
    "        df[col] = df[col].clip(upper=max_val)\n",
    "    return df\n",
    "\n",
    "def validate_coordinates(df, lat_cols, lon_cols):\n",
    "    for lat in lat_cols:\n",
    "        df.loc[~df[lat].between(-11, 6), lat] = np.nan\n",
    "    for lon in lon_cols:\n",
    "        df.loc[~df[lon].between(95, 141), lon] = np.nan\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6779ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING FUNCTIONS\n",
    "\n",
    "def clean_fleet(df):\n",
    "    df = df.copy()\n",
    "    df = to_datetime(df, [\"week_start\"])\n",
    "    numeric_cols = [\n",
    "    \"available_trucks\", \"breakdown_trucks\", \"utilization_pct\",\n",
    "    \"capacity_ton\", \"effective_capacity_ton\", \"tonnage_last_week\"\n",
    "]\n",
    "    df = to_numeric(df, numeric_cols)\n",
    "    df = clip_numeric(df, \"utilization_pct\", 0, 100)\n",
    "    return df\n",
    "\n",
    "def clean_heavy_equipment(df):\n",
    "    df = df.copy()\n",
    "    df = to_datetime(df, [\"week_start\"])\n",
    "    numeric_cols = [\n",
    "    \"excavator_active\", \"dozer_active\", \"grader_active\",\n",
    "    \"maintenance_units\", \"avg_operating_hours\", \"potential_breakdown_flag\"\n",
    "]\n",
    "    df = to_numeric(df, numeric_cols)\n",
    "    df = clip_numeric(df, \"avg_operating_hours\", 0, 24)\n",
    "    return df\n",
    "\n",
    "def clean_production(df):\n",
    "    df = df.copy()\n",
    "    df = to_datetime(df, [\"week_start\"])\n",
    "    numeric_cols = numeric_cols = [\"target_ton\", \"progress_ratio\", \"realized_ton\"]\n",
    "    df = to_numeric(df, numeric_cols)\n",
    "    return df\n",
    "\n",
    "def clean_road(df):\n",
    "    df = df.copy()\n",
    "    cat_cols = [\"road_id\", \"segment_name\", \"segment_type\", \"surface_type\", \"curvature_level\"]\n",
    "    df = clean_category(df, cat_cols)\n",
    "    numeric_cols = [\"length_km\", \"slope_pct\", \"elevation_start_m\", \"elevation_end_m\"]\n",
    "    df = to_numeric(df, numeric_cols)\n",
    "    df = clip_numeric(df, \"slope_pct\", 0, 35)\n",
    "    df[\"elevation_gain_m\"] = df[\"elevation_end_m\"] - df[\"elevation_start_m\"]\n",
    "    df[\"is_climbing\"] = (df[\"elevation_gain_m\"] > 0).astype(int)\n",
    "    df = to_numeric(df, [\"lat_start\", \"lon_start\", \"lat_end\", \"lon_end\"])\n",
    "    df = validate_coordinates(df, [\"lat_start\", \"lat_end\"], [\"lon_start\", \"lon_end\"])\n",
    "    return df\n",
    "\n",
    "def clean_ship_schedule(df):\n",
    "    df = df.copy()\n",
    "    df = to_datetime(df, [\"week_start\", \"eta\", \"etd\"])\n",
    "    df = clean_category(df, [\"ship_size\", \"jetty_id\"])\n",
    "    numeric_cols = [\"ship_size\"] \n",
    "    df = to_numeric(df, numeric_cols)\n",
    "    return df\n",
    "\n",
    "def clean_stockpile(df):\n",
    "    df = df.copy()\n",
    "    df = clean_category(df, [\"stockpile_id\"])\n",
    "    df = to_datetime(df, [\"week_start\"])\n",
    "    numeric_cols = [\n",
    "        \"current_stock_ton\", \"incoming_production_ton\",\n",
    "        \"planned_loading_ton\", \"stock_after_loading_ton\"\n",
    "    ]\n",
    "    df = to_numeric(df, numeric_cols)\n",
    "    return df\n",
    "\n",
    "def clean_truck_to_ship(df):\n",
    "    df = df.copy()\n",
    "    df = to_datetime(df, [\"week_start\"])\n",
    "    df = clean_category(df, [\"truck_id\", \"jetty_id\"])\n",
    "    numeric_cols = [\n",
    "        \"allocated_for_shipping\", \"avg_cycle_time_min\",\n",
    "        \"trip_count\", \"tonnage_moved_ton\",\n",
    "        \"road_flood_flag\", \"crossing_queue_flag\"\n",
    "    ]\n",
    "    df = to_numeric(df, numeric_cols)\n",
    "    return df\n",
    "\n",
    "def clean_weather(df):\n",
    "    df = df.copy()\n",
    "    df = to_datetime(df, [\"date\"])\n",
    "    df = clean_category(df, [\"location\"])\n",
    "    numeric_cols = [\n",
    "        \"lat\", \"lon\", \"rainfall_mm\", \"humidity_pct\",\n",
    "        \"solar_radiation_wm2\", \"temp_c\", \"temp_max_c\",\n",
    "        \"temp_min_c\", \"wind_speed_10m_mps\", \"cloud_cover_pct\"\n",
    "    ]\n",
    "    df = to_numeric(df, numeric_cols)\n",
    "    df = validate_coordinates(df, [\"lat\"], [\"lon\"])\n",
    "    df = clip_numeric(df, \"humidity_pct\", 0, 100)\n",
    "    df = clip_numeric(df, \"cloud_cover_pct\", 0, 100)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c592d980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD RAW DATA\n",
    "fleet_files           = load_all_files(\"fleet\")\n",
    "heavy_equipment_files = load_all_files(\"heavy_equipment\")\n",
    "production_files      = load_all_files(\"production\")\n",
    "weather_files         = load_all_files(\"weather\")\n",
    "road_files            = load_all_files(\"road\")\n",
    "truck_to_ship_files   = load_all_files(\"truck_to_ship\")\n",
    "ship_schedule_files   = load_all_files(\"ship_schedule\")\n",
    "stockpile_files       = load_all_files(\"stockpile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bdd002c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fleet cleaned & saved successfully\n",
      "[INFO] heavy_equipment cleaned & saved successfully\n",
      "[INFO] production cleaned & saved successfully\n",
      "[INFO] weather cleaned & saved successfully\n",
      "[INFO] road cleaned & saved successfully\n",
      "[INFO] truck_to_ship cleaned & saved successfully\n",
      "[INFO] ship_schedule cleaned & saved successfully\n",
      "[INFO] stockpile cleaned & saved successfully\n"
     ]
    }
   ],
   "source": [
    "# CLEAN & SAVE\n",
    "domain_map = [\n",
    "    (\"fleet\", fleet_files, clean_fleet),\n",
    "    (\"heavy_equipment\", heavy_equipment_files, clean_heavy_equipment),\n",
    "    (\"production\", production_files, clean_production),\n",
    "    (\"weather\", weather_files, clean_weather),\n",
    "    (\"road\", road_files, clean_road),\n",
    "    (\"truck_to_ship\", truck_to_ship_files, clean_truck_to_ship),\n",
    "    (\"ship_schedule\", ship_schedule_files, clean_ship_schedule),\n",
    "    (\"stockpile\", stockpile_files, clean_stockpile)\n",
    "]\n",
    "\n",
    "for domain_name, files_dict, clean_func in domain_map:\n",
    "    for fname, df in files_dict.items():\n",
    "        try:\n",
    "            df_clean = clean_func(df)\n",
    "            # Save ke CSV\n",
    "            df_clean.to_csv(BASE_CLEAN / f\"{fname}.csv\", index=False)\n",
    "            print(f\"[INFO] {fname} cleaned & saved successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {fname} cleaning failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36b69036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== File: fleet.csv ===\n",
      "Shape: (144, 9)\n",
      "Columns: ['week_start', 'pit_id', 'available_trucks', 'breakdown_trucks', 'utilization_pct', 'capacity_ton', 'effective_capacity_ton', 'tonnage_last_week', 'predicted_repair_hours']\n",
      "Data types:\n",
      " week_start                datetime64[ns]\n",
      "pit_id                            object\n",
      "available_trucks                   int64\n",
      "breakdown_trucks                   int64\n",
      "utilization_pct                  float64\n",
      "capacity_ton                       int64\n",
      "effective_capacity_ton           float64\n",
      "tonnage_last_week                  int64\n",
      "predicted_repair_hours           float64\n",
      "dtype: object\n",
      "\n",
      "Head:\n",
      "   week_start pit_id  available_trucks  breakdown_trucks  utilization_pct  \\\n",
      "0 2023-01-02  PIT-1                24                 2            81.11   \n",
      "1 2023-01-09  PIT-1                28                 3            91.19   \n",
      "2 2023-01-16  PIT-1                18                 2            72.86   \n",
      "3 2023-01-23  PIT-1                31                 0            81.70   \n",
      "4 2023-01-30  PIT-1                20                 3            90.44   \n",
      "\n",
      "   capacity_ton  effective_capacity_ton  tonnage_last_week  \\\n",
      "0            45                  876.04              10000   \n",
      "1            45                 1148.96               9266   \n",
      "2            50                  655.77               9281   \n",
      "3            50                 1266.29              10128   \n",
      "4            45                  813.96              10195   \n",
      "\n",
      "   predicted_repair_hours  \n",
      "0                6.299674  \n",
      "1               17.898750  \n",
      "2                8.797880  \n",
      "3               12.701389  \n",
      "4               10.010415  \n",
      "\n",
      "Missing values:\n",
      " week_start                0\n",
      "pit_id                    0\n",
      "available_trucks          0\n",
      "breakdown_trucks          0\n",
      "utilization_pct           0\n",
      "capacity_ton              0\n",
      "effective_capacity_ton    0\n",
      "tonnage_last_week         0\n",
      "predicted_repair_hours    0\n",
      "dtype: int64\n",
      "\n",
      "=== File: heavy_equipment.csv ===\n",
      "Shape: (144, 9)\n",
      "Columns: ['week_start', 'pit_id', 'excavator_active', 'dozer_active', 'grader_active', 'maintenance_units', 'avg_operating_hours', 'fuel_burn_rate_lph', 'potential_breakdown_flag']\n",
      "Data types:\n",
      " week_start                   object\n",
      "pit_id                       object\n",
      "excavator_active              int64\n",
      "dozer_active                  int64\n",
      "grader_active                 int64\n",
      "maintenance_units             int64\n",
      "avg_operating_hours         float64\n",
      "fuel_burn_rate_lph          float64\n",
      "potential_breakdown_flag      int64\n",
      "dtype: object\n",
      "\n",
      "Head:\n",
      "    week_start pit_id  excavator_active  dozer_active  grader_active  \\\n",
      "0  2023-01-02  PIT-1                21            13              3   \n",
      "1  2023-01-09  PIT-1                18             8              5   \n",
      "2  2023-01-16  PIT-1                22             8              5   \n",
      "3  2023-01-23  PIT-1                19             8              4   \n",
      "4  2023-01-30  PIT-1                21            10              5   \n",
      "\n",
      "   maintenance_units  avg_operating_hours  fuel_burn_rate_lph  \\\n",
      "0                  3                 17.5                18.3   \n",
      "1                  9                 16.7                24.0   \n",
      "2                  4                 16.1                23.7   \n",
      "3                  8                 14.7                28.0   \n",
      "4                  8                 14.4                21.7   \n",
      "\n",
      "   potential_breakdown_flag  \n",
      "0                         0  \n",
      "1                         0  \n",
      "2                         0  \n",
      "3                         0  \n",
      "4                         0  \n",
      "\n",
      "Missing values:\n",
      " week_start                  0\n",
      "pit_id                      0\n",
      "excavator_active            0\n",
      "dozer_active                0\n",
      "grader_active               0\n",
      "maintenance_units           0\n",
      "avg_operating_hours         0\n",
      "fuel_burn_rate_lph          0\n",
      "potential_breakdown_flag    0\n",
      "dtype: int64\n",
      "\n",
      "=== File: production.csv ===\n",
      "Shape: (144, 7)\n",
      "Columns: ['week_start', 'pit_id', 'stockpile', 'target_ton', 'progress_ratio', 'realized_ton', 'differential']\n",
      "Data types:\n",
      " week_start        datetime64[ns]\n",
      "pit_id                    object\n",
      "stockpile                 object\n",
      "target_ton                 int64\n",
      "progress_ratio           float64\n",
      "realized_ton               int64\n",
      "differential               int64\n",
      "dtype: object\n",
      "\n",
      "Head:\n",
      "   week_start pit_id stockpile  target_ton  progress_ratio  realized_ton  \\\n",
      "0 2023-01-02  PIT-1      SP-1        9860           0.889          8761   \n",
      "1 2023-01-09  PIT-1      SP-1       12772           0.858         10955   \n",
      "2 2023-01-16  PIT-1      SP-1       12092           0.793          9592   \n",
      "3 2023-01-23  PIT-1      SP-1        9466           0.760          7189   \n",
      "4 2023-01-30  PIT-1      SP-1       13426           0.831         11162   \n",
      "\n",
      "   differential  \n",
      "0         -1099  \n",
      "1         -1817  \n",
      "2         -2500  \n",
      "3         -2277  \n",
      "4         -2264  \n",
      "\n",
      "Missing values:\n",
      " week_start        0\n",
      "pit_id            0\n",
      "stockpile         0\n",
      "target_ton        0\n",
      "progress_ratio    0\n",
      "realized_ton      0\n",
      "differential      0\n",
      "dtype: int64\n",
      "\n",
      "=== File: road.csv ===\n",
      "Shape: (5, 17)\n",
      "Columns: ['road_id', 'segment_name', 'segment_type', 'surface_type', 'length_km', 'slope_pct', 'curvature_level', 'roughness_index', 'waterlogging_risk', 'elevation_start_m', 'elevation_end_m', 'lat_start', 'lon_start', 'lat_end', 'lon_end', 'elevation_gain_m', 'is_climbing']\n",
      "Data types:\n",
      " road_id               object\n",
      "segment_name          object\n",
      "segment_type          object\n",
      "surface_type          object\n",
      "length_km            float64\n",
      "slope_pct            float64\n",
      "curvature_level       object\n",
      "roughness_index      float64\n",
      "waterlogging_risk     object\n",
      "elevation_start_m      int64\n",
      "elevation_end_m        int64\n",
      "lat_start            float64\n",
      "lon_start            float64\n",
      "lat_end              float64\n",
      "lon_end              float64\n",
      "elevation_gain_m       int64\n",
      "is_climbing            int64\n",
      "dtype: object\n",
      "\n",
      "Head:\n",
      "   road_id                 segment_name segment_type surface_type  length_km  \\\n",
      "0    r-01    pit_entrance_→_active_pit        inpit     laterite       2.64   \n",
      "1    r-02             active_pit_→_rom         ramp       gravel       4.57   \n",
      "2    r-03              rom_→_stockpile    main_haul    hard-rock       4.95   \n",
      "3    r-04    stockpile_→_jetty_primary   jetty_road     coal_ash       3.81   \n",
      "4    r-05  stockpile_→_jetty_secondary   jetty_road     coal_ash       5.98   \n",
      "\n",
      "   slope_pct curvature_level  roughness_index waterlogging_risk  \\\n",
      "0  13.408572            high             2.99               low   \n",
      "1   7.510987             low             2.58              high   \n",
      "2  13.262633          medium             1.62               low   \n",
      "3   2.084796             low             1.87              high   \n",
      "4   4.793256          medium             3.01              high   \n",
      "\n",
      "   elevation_start_m  elevation_end_m  lat_start  lon_start  lat_end  lon_end  \\\n",
      "0                 78               60     -0.456     117.11   -0.470  117.130   \n",
      "1                 61               43     -0.470     117.13   -0.490  117.170   \n",
      "2                 72               53     -0.490     117.17   -0.505  117.210   \n",
      "3                 81               69     -0.505     117.21   -0.520  117.240   \n",
      "4                 83               44     -0.505     117.21   -0.525  117.255   \n",
      "\n",
      "   elevation_gain_m  is_climbing  \n",
      "0               -18            0  \n",
      "1               -18            0  \n",
      "2               -19            0  \n",
      "3               -12            0  \n",
      "4               -39            0  \n",
      "\n",
      "Missing values:\n",
      " road_id              0\n",
      "segment_name         0\n",
      "segment_type         0\n",
      "surface_type         0\n",
      "length_km            0\n",
      "slope_pct            0\n",
      "curvature_level      0\n",
      "roughness_index      0\n",
      "waterlogging_risk    0\n",
      "elevation_start_m    0\n",
      "elevation_end_m      0\n",
      "lat_start            0\n",
      "lon_start            0\n",
      "lat_end              0\n",
      "lon_end              0\n",
      "elevation_gain_m     0\n",
      "is_climbing          0\n",
      "dtype: int64\n",
      "\n",
      "=== File: ship_schedule.csv ===\n",
      "Shape: (387, 10)\n",
      "Columns: ['week_start', 'eta', 'etd', 'ship_size', 'jetty_id', 'loading_rate_tph', 'est_loading_hours', 'weather_delay_h', 'queue_delay_h', 'planned_load']\n",
      "Data types:\n",
      " week_start            object\n",
      "eta                   object\n",
      "etd                   object\n",
      "ship_size              int64\n",
      "jetty_id              object\n",
      "loading_rate_tph       int64\n",
      "est_loading_hours    float64\n",
      "weather_delay_h        int64\n",
      "queue_delay_h          int64\n",
      "planned_load           int64\n",
      "dtype: object\n",
      "\n",
      "Head:\n",
      "    week_start         eta                  etd  ship_size       jetty_id  \\\n",
      "0  2023-01-02  2023-01-05  2023-01-05 22:00:00      55000  jetty_primary   \n",
      "1  2023-01-02  2023-01-03  2023-01-04 02:00:00      65000  jetty_primary   \n",
      "2  2023-01-09  2023-01-12  2023-01-13 18:00:00      65000  jetty_primary   \n",
      "3  2023-01-09  2023-01-10  2023-01-11 00:00:00      60000  jetty_primary   \n",
      "4  2023-01-09  2023-01-10  2023-01-10 22:00:00      55000  jetty_primary   \n",
      "\n",
      "   loading_rate_tph  est_loading_hours  weather_delay_h  queue_delay_h  \\\n",
      "0              2500               22.0                0              0   \n",
      "1              2500               26.0                0              0   \n",
      "2              2500               26.0               12              4   \n",
      "3              2500               24.0                0              0   \n",
      "4              2500               22.0                0              0   \n",
      "\n",
      "   planned_load  \n",
      "0         55000  \n",
      "1         65000  \n",
      "2         65000  \n",
      "3         60000  \n",
      "4         55000  \n",
      "\n",
      "Missing values:\n",
      " week_start           0\n",
      "eta                  0\n",
      "etd                  0\n",
      "ship_size            0\n",
      "jetty_id             0\n",
      "loading_rate_tph     0\n",
      "est_loading_hours    0\n",
      "weather_delay_h      0\n",
      "queue_delay_h        0\n",
      "planned_load         0\n",
      "dtype: int64\n",
      "\n",
      "=== File: stockpile.csv ===\n",
      "Shape: (144, 7)\n",
      "Columns: ['week_start', 'pit_id', 'stockpile_id', 'current_stock_ton', 'incoming_production_ton', 'planned_loading_ton', 'stock_after_loading_ton']\n",
      "Data types:\n",
      " week_start                 datetime64[ns]\n",
      "pit_id                             object\n",
      "stockpile_id                       object\n",
      "current_stock_ton                   int64\n",
      "incoming_production_ton             int64\n",
      "planned_loading_ton                 int64\n",
      "stock_after_loading_ton             int64\n",
      "dtype: object\n",
      "\n",
      "Head:\n",
      "   week_start pit_id stockpile_id  current_stock_ton  incoming_production_ton  \\\n",
      "0 2023-01-02  PIT-1         sp-1              63654                    45795   \n",
      "1 2023-01-09  PIT-1         sp-1              88589                    68158   \n",
      "2 2023-01-16  PIT-1         sp-1              92015                    41284   \n",
      "3 2023-01-23  PIT-1         sp-1             107034                    46850   \n",
      "4 2023-01-30  PIT-1         sp-1              96690                    51962   \n",
      "\n",
      "   planned_loading_ton  stock_after_loading_ton  \n",
      "0                20860                    88589  \n",
      "1                64732                    92015  \n",
      "2                26265                   107034  \n",
      "3                57194                    96690  \n",
      "4                67191                    81461  \n",
      "\n",
      "Missing values:\n",
      " week_start                 0\n",
      "pit_id                     0\n",
      "stockpile_id               0\n",
      "current_stock_ton          0\n",
      "incoming_production_ton    0\n",
      "planned_loading_ton        0\n",
      "stock_after_loading_ton    0\n",
      "dtype: int64\n",
      "\n",
      "=== File: truck_to_ship.csv ===\n",
      "Shape: (2880, 9)\n",
      "Columns: ['week_start', 'truck_id', 'allocated_for_shipping', 'avg_cycle_time_min', 'trip_count', 'tonnage_moved_ton', 'road_flood_flag', 'crossing_queue_flag', 'jetty_id']\n",
      "Data types:\n",
      " week_start                 object\n",
      "truck_id                   object\n",
      "allocated_for_shipping      int64\n",
      "avg_cycle_time_min          int64\n",
      "trip_count                  int64\n",
      "tonnage_moved_ton         float64\n",
      "road_flood_flag             int64\n",
      "crossing_queue_flag         int64\n",
      "jetty_id                   object\n",
      "dtype: object\n",
      "\n",
      "Head:\n",
      "    week_start      truck_id  allocated_for_shipping  avg_cycle_time_min  \\\n",
      "0  2023-01-02   shiptruck_1                       1                 117   \n",
      "1  2023-01-02  shiptruck_14                       1                  99   \n",
      "2  2023-01-02   shiptruck_9                       1                  96   \n",
      "3  2023-01-02   shiptruck_2                       1                 115   \n",
      "4  2023-01-02  shiptruck_16                       1                  92   \n",
      "\n",
      "   trip_count  tonnage_moved_ton  road_flood_flag  crossing_queue_flag  \\\n",
      "0          15              460.3                0                    0   \n",
      "1          30              719.5                1                    0   \n",
      "2          23              607.0                1                    0   \n",
      "3          16              391.6                0                    0   \n",
      "4          28              613.1                0                    0   \n",
      "\n",
      "        jetty_id  \n",
      "0  jetty_primary  \n",
      "1  jetty_primary  \n",
      "2  jetty_primary  \n",
      "3  jetty_primary  \n",
      "4  jetty_primary  \n",
      "\n",
      "Missing values:\n",
      " week_start                0\n",
      "truck_id                  0\n",
      "allocated_for_shipping    0\n",
      "avg_cycle_time_min        0\n",
      "trip_count                0\n",
      "tonnage_moved_ton         0\n",
      "road_flood_flag           0\n",
      "crossing_queue_flag       0\n",
      "jetty_id                  0\n",
      "dtype: int64\n",
      "\n",
      "=== File: weather.csv ===\n",
      "Shape: (6030, 12)\n",
      "Columns: ['date', 'location', 'lat', 'lon', 'rainfall_mm', 'humidity_pct', 'solar_radiation_wm2', 'temp_c', 'temp_max_c', 'temp_min_c', 'wind_speed_10m_mps', 'cloud_cover_pct']\n",
      "Data types:\n",
      " date                   datetime64[ns]\n",
      "location                       object\n",
      "lat                           float64\n",
      "lon                           float64\n",
      "rainfall_mm                   float64\n",
      "humidity_pct                  float64\n",
      "solar_radiation_wm2           float64\n",
      "temp_c                        float64\n",
      "temp_max_c                    float64\n",
      "temp_min_c                    float64\n",
      "wind_speed_10m_mps            float64\n",
      "cloud_cover_pct               float64\n",
      "dtype: object\n",
      "\n",
      "Head:\n",
      "         date      location    lat     lon  rainfall_mm  humidity_pct  \\\n",
      "0 2023-01-01  pit_entrance -0.456  117.11         0.26         86.77   \n",
      "1 2023-01-02  pit_entrance -0.456  117.11         4.82         92.03   \n",
      "2 2023-01-03  pit_entrance -0.456  117.11         1.19         91.48   \n",
      "3 2023-01-04  pit_entrance -0.456  117.11         0.10         88.63   \n",
      "4 2023-01-05  pit_entrance -0.456  117.11         0.34         90.13   \n",
      "\n",
      "   solar_radiation_wm2  temp_c  temp_max_c  temp_min_c  wind_speed_10m_mps  \\\n",
      "0                19.96   26.23       30.07       22.92                0.73   \n",
      "1                18.62   25.63       27.71       24.15                0.69   \n",
      "2                13.48   25.55       28.58       23.00                0.71   \n",
      "3                19.21   25.76       29.31       22.79                0.85   \n",
      "4                18.42   25.58       27.90       23.37                0.58   \n",
      "\n",
      "   cloud_cover_pct  \n",
      "0            93.21  \n",
      "1            94.26  \n",
      "2            98.84  \n",
      "3            96.62  \n",
      "4            86.90  \n",
      "\n",
      "Missing values:\n",
      " date                   0\n",
      "location               0\n",
      "lat                    0\n",
      "lon                    0\n",
      "rainfall_mm            0\n",
      "humidity_pct           0\n",
      "solar_radiation_wm2    0\n",
      "temp_c                 0\n",
      "temp_max_c             0\n",
      "temp_min_c             0\n",
      "wind_speed_10m_mps     0\n",
      "cloud_cover_pct        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# LOAD CLEAN DATA & VERIFY\n",
    "datetime_cols = {\n",
    "    \"fleet\": [\"week_start\"],\n",
    "    \"heavy_equipment\": [\"week_start\"],\n",
    "    \"production\": [\"week_start\"],\n",
    "    \"road\": [],\n",
    "    \"truck_to_ship\": [\"week_start\"],\n",
    "    \"ship_schedule\": [\"week_start\", \"eta\", \"etd\"],\n",
    "    \"stockpile\": [\"week_start\"],\n",
    "    \"weather\": [\"date\"]\n",
    "}\n",
    "\n",
    "for f in BASE_CLEAN.glob(\"*.csv\"):\n",
    "    domain_name = f.stem.split(\"_\")[0]  # misal 'fleet_xyz' → 'fleet'\n",
    "    parse_cols = datetime_cols.get(domain_name, [])\n",
    "    \n",
    "    df = pd.read_csv(f, parse_dates=parse_cols)  # parse datetime\n",
    "    print(f\"\\n=== File: {f.name} ===\")\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(\"Columns:\", df.columns.tolist())\n",
    "    print(\"Data types:\\n\", df.dtypes)\n",
    "    print(\"\\nHead:\\n\", df.head())\n",
    "    print(\"\\nMissing values:\\n\", df.isna().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
